\chapter{Methodology and Design}
Methodology is the systematic, theoretical analysis of the methods applied to develop a project. It comprises the theoretical analysis of the body of methods and principles associated with a branch of knowledge. Typically, it encompasses concepts such as paradigm, theoretical model, phases and quantitative or qualitative techniques.
\par
System design is the process of defining the architecture, components, modules, interfaces, and data for a system to satisfy specified requirements. Systems design could be seen as the application of systems theory to product development.
\section{System Design}
The project focuses on the implementation of an algorithm that can detect disturbance in crowd. The design of the project is shown in Fig. 3.1. It considers how flow-vector magnitudes change over time, which are collected for short frame sequences, and then classified as either normal or abnormal situation using a classifier.
\par
The aim of the project is to keep the processing very quick, a detection should be made within a few seconds of the outbreak of violence. It has to detect the change of normal behaviour to abnormal behaviour with the shortest delay from the time that the change has occurred.

\begin{figure}[H]
\centering
\includegraphics[scale = 0.4]{system_design.png}
\caption{System Design}
\end{figure}

\section{Implementation of Proposed Solution}
\subsection{Input Footage}
For training of the classifier, input of the footage will be from a fixed dataset. For practical real time implementation, footage from externally attached cameras can be used. The resolution of the input footage need not be specific. Generally the resolution of a CCTV footage is of 704 X 480 pixels. This proposed algorithm reduces the height of the video to 100 pixels and width accordingly. This increases the scalability of the algorithm. Even high definition videos can be processed with the proposed algorithm.
\subsection{Preprocessing}
Preprocessing the input data is very important part of the algorithm. Optical flow algorithm will take at least one minute to calculate optical flow of a high definition image. So as to constraint the processing to real time, preprocessing must done. As mentioned earlier any image is being resized to 100 pixels height and respective width accordingly. Preprocessing is done in a way such that the aspect ratio of the video is not disturbed.
\subsection{Flow Vector Magnitude}
Each pixel in the video has some velocity corresponding to it, along x direction and y direction. The Flow Vector Magnitude is nothing but the magnitudes of these velocities. Computing Flow Vector Magnitude is computationally heavy and this is the most time taking part of the proposed algorithm. Since we are reducing the size of frames considerably, this computation is quick enough to cope us with real time violence detection.
\subsection{Feature Extraction}
Feature extraction is based on the computation of ViF (Violence Flow Descriptors)\cite{hassner}. These descriptors are quantised values of the above generated Flow Vector Magnitudes. After ViF is generated a histogram is built which will assign different ViF values to corresponding bins in the range of 0 - 1.0 with the intervals of 0.05, i.e 20 bins.
\subsection{Classification}
After the features have been extracted, classification can done with the help of a simple Linear SVM. So as to further increase the accuracy of the algorithm , SVM with AdaBoost can be used. For our project a trained neural net has been used, since it is providing a better accuracy.
\subsection{Detection}
Detection in a video footage is the final output of the proposed algorithm. It is taking place with the help classifier model that is being trained in the above step. According to the base paper, a sequence of 10 frames i.e on an average two-fifth of a second is enough to detect violence in a footage. Detection may be further improved by continuous training of neural net in real-time also.
\section{Dataset}
In-the-wild violence dataset is chosen as dataset for the project. The dataset consists of 246 videos in which half are violent and other half are non-violent. The video duration range from 1.04 sec to 6.52 sec with an average duration of 3.60 sec as shown in Fig. 3.2. All the videos are downloaded from YouTube which are produced under in-the-wild and uncontrolled conditions presenting a wide range of real-world viewing conditions, video qualities and surveillance scenarios. Videos are compressed using the DivX codec (mpeg4) and resized to 240 X 320 pixels.

\begin{center}
\begin{figure}[H]
\centering
\includegraphics{dataset.png}
\caption{Dataset}
\end{figure}
\end{center}
\section{Data Flow Diagram}
A data flow diagram is a graphical representation of the "flow" of data through an information system, modelling its process aspects. A DFD is often used as a preliminary step to create an overview of the system without going into great detail, which can later be elaborated. DFD's can be used for the visualization of data processing. Level-0 DFD of the proposed system is shown in the Fig. 3.3.
\par
Data flow diagrams are also known as bubble charts. DFD is a designing tool used in the top-down approach to system design. This context-level DFD is next "exploded", to produce a level-1 DFD that shows some of the detail of the system being modeled. The Level-1 DFD shows how the system is divided into subsystems, each of which deals with one or more of the data flows to from an external agent, and which together provide all of the functionality of the system as a whole. It also identifies internal data stores that must be present in order for the system to do its job, and shows the flow of data between the various parts of the system. Level-1 DFD of the proposed system is shown in the Fig. 3.4.

\begin{center}
\begin{figure}[H]
\centering
\includegraphics[width = \linewidth]{dfd0.png}
\caption{Data Flow Diagram Level 0 of the proposed system}
\end{figure}
\end{center}

\begin{center}
\begin{figure}[H]
\centering
\includegraphics[width = \linewidth]{dfd1.png}
\caption{Data Flow Diagram Level 1 of the proposed system}
\end{figure}
\end{center}

\section{UML Diagrams}
UML stands for Unified Modeling Language. UML is a standardized general-purpose modeling language in the field of object-oriented software engineering. The standard is managed, and was created by, the Object Management Group. 
\par
The UML is a very important part of developing object oriented software and the software development process. The UML uses mostly graphical notations to express the design of software projects.\\
\subsection{Building blocks of UML}
The vocabulary of the UML encompasses three kinds of building blocks.
\begin{enumerate}
	\item Things.
	\item Relationships.
	\item Diagrams.
\end{enumerate}
\subsection{Things in UML}
Things are the abstractions that are first-class citizen in a model.\\
There are four kinds of things in the UML.
\begin{enumerate}
	\item Structural things.
	\item Behavioural things.
	\item Grouping things.
	\item Annotational things.
\end{enumerate}
These things are the basic object-oriented building blocks of the UML. We use them to write well-formed models.
\subsection{Relationships in the UML}
Things can be connected to logically be physically with the help of relationship in object oriented modelling.These are four kinds of relationships in the UML.

\begin{enumerate}
	\item Dependency.
	\item Association.
	\item Generalization.
	\item Realization.
\end{enumerate}
\subsection{Diagrams in UML}
A diagram is a graphical representation of a set of elements. These are nine kinds of diagrams in the UML.
\begin{enumerate}
	\item Class diagram.                 
\item  Object diagram                
\item  Use Case diagram.               
\item  Sequence diagram.             
\item  Collaboration diagram.
\item  Activity diagram.
\item  Component diagram.
\item  State chart diagram.
\item  Deployment diagram.

\end{enumerate}
\subsection{Component Diagram}
Component diagram of the proposed system is shown in Fig. 3.5. It has the following components:
\begin{enumerate}
	\item OpenCV
	\item Bob
	\item Video Preprocess
	\item Optical Flow
	\item Violent Feature Extract
\end{enumerate}
\begin{center}
\begin{figure}[H]
\centering
\includegraphics[width = \linewidth]{component.png}
\caption{Component Diagram of the proposed system}
\end{figure}
\end{center}
\subsubsection{OpenCV}
OpenCV (short for Open Computer Vision)\cite{opencv} is a package originally written in C language but later it was ported to Python. OpenCV possesses a rich set of interfaces and functions  that help us to read and manipulate video files. OpenCV can read video from input cameras and also from attached cameras to the system. Given a source of CCTV footage , through OpenCV we are able to manipulate frame size, the colour and the frame intervals. Video Preprocessing has to be done so that the further components can work at real-time which is on and average 1/25 th of a second for a frame.
\subsubsection{Bob}
Bob\cite{bob} is a signal processing and machine learning platform available for python. Bob is provided as a precompiled source for Linux or Mac OS through Anaconda package manager. Bob helps us to port the signal processing procedures which are initially written in C language. Signal processing methods are usually written in C language as it can make native function calls and kernel function calls. So as to port these procedures into Python bob platform is used. C Liu's Optical Flow algorithm[5] is being ported here through bob.
\subsubsection{Video Preprocess}
This is a self written Python library. It Preprocesses the video according to our needs. This library makes the necessary calls from the OpenCV so as to do the pixel level manipulations. Frame by Frame access is done through this package. Frame interval is set as 3, default frame rate is taken as 25, each frame is resized to 100 pixel width and corresponding height. Frame is further converted into grayscale.
\subsubsection{Optical Flow}
This is also a self written package. It contains the procedures to calculate Optical flow\cite{liu} which further call procedures from bob platform. Optical flow will return 3 things in a tuple, velocity along x axis , y axis and the wrap. This calculation is done by considering some pre calculated parameters.
\subsubsection{Video Feature Extract}
At a considered moment, three frames are under consideration, previous frame , current frame and the next frame. First thing we do is we preprocess these frames and then calculated optical flows between successive frames. Now we have two optical flow vectors, now we calculate the absolute change between these two vectors. Average of this change vector is calculated and it is stored as threshold. Now the change vector is quantised with binary 1 and 0 by comparing it with threshold vector. This binary vector is summed for the whole video and normalized by dividing it with the number of iterations done till now. Binary vector generated till now is divided into (4 * 4) parts. For each of these parts , a histogram is built which has the bin size of 0.05 ranging from 0 to 1. Frequency of each bin is calculated and normalized by dividing with sum of all frequencies. Now all of the normalized histograms are appended one after another and the resulting vector is known as \textit{Violent Feature Vector}.



\section{Requirements, Analysis and Specifications}
\subsection{Unix}
Unix is a family of multitasking, multiuser computer operating systems that derive from the original AT\&T Unix, development starting in the 1970s at the Bell Labs research center by Ken Thompson, Dennis Ritchie, and others.
Unix was originally meant to be a basic platform for programmers developing software to be run on it and on other systems, rather than others. The system grew larger as the operating system started spreading in academic circles, as users added their own tools to the system and shared them with colleagues. The best feature of linux is that it is open source. Being open source makes anyone in the world to contribute to it. This makes unix highly robust and stable.  
\begin{itemize}
	\item Kernel - /usr/sys which contains the sub-components.
	\item Development Env - Linux code itself can be built in the linux. Provdes great environment for the programmers.
	\item Commands in Linux - \begin{itemize}
	\item  for system operation and maintenance, \item commands of general utility\item general-purpose applications  \item text formatting and \item typesetting package. 
	\item Document formatting - Unix systems were used  for document preparation and typesetting systems, and included many related programs such as nroff, troff, tbl, eqn, refer, and pic. Some modern Unix systems also include packages such as TeX and Ghostscript.
	\item Graphics - the plot subsystem provided facilities for producing simple vector plots in a device-independent format, with device-specific interpreters to display such files. Modern Unix systems also generally include X11 as a standard windowing system and GUI, and many support OpenGL.
	\item Communications - early Unix systems contained no inter-system communication, but did include the inter-user communication programs mail and write. V7 introduced the early inter-system communication system UUCP, and systems beginning with BSD release 4.1c included TCP/IP utilities.
\end{itemize}
\item Multiple Development Environments
\item Multithreaded Programming
\item Manipulation of Device Drivers
\item Support for latest languages and packages
\end{itemize}
\subsection{Python}
Only open source languages and tools are used in developing the project. Unix environment is being used for the development of the process.
Language used is Python and the main tool used is OpenCV for video processing. Python is interpreted language which is used for general-purpose programming. It is a user-friendly language which emphasizes on code readability and its syntax allows users to write programs with relatively fewer lines of code when compared to C/C++, Java etc. Python 2.7 version is used in the project.\\
Python's \textbf{features} include:
\begin{itemize}
\item East Learning: Python has less keywords, simple structure, and a clearly defined syntax. This allows to pick up the language quickly.
\item Scripting Language: Python code is more clearly defined and visible to the eyes. Since it is scripting language it can be easily read.
\item Maintenance: Python code is fairly easy-to-maintain.
\item A broad collection of standard library: Python's bulk of the library is very portable and cross-platform compatible on UNIX, Windows, and Macintosh. It uses the pip package for maintenance and installation of those standard packages.
\item Interactive Mode: Python has support for an interactive mode which allows interactive testing and debugging of snippets of code through tools such as iPython notebooks.
\item Portability: Python can run on a wide variety of hardware and has the same interpretation on all platforms.
\item Extendable Interpretation: You can add low-level modules to the Python interpreter. These modules enable programmers to add to or customize their tools to be more efficient.
\item Database Support: Python provides interfaces to all commercial databases such as Oracle, MySQL.
\item GUI Programming: Python supports GUI applications that can be created and ported to many system calls, libraries and windows systems, such as Windows MFC, Macintosh, and the X Window system of Unix.
\item Scalability: Python programs are highly scalable. They provide better structure and support than Shell Scripting.
\end{itemize}
Apart from the above-mentioned features, Python has a big list of good features, few are listed below:
\begin{itemize}
	\item It supports functional and structured programming methods as well as OOP.
\item It can be used as a scripting language or can be compiled to byte-code for building large applications.
\item It provides very high-level dynamic data types and supports dynamic type checking.
\item It supports automatic garbage collection.
\item It can be easily integrated with C, C++, COM, ActiveX, CORBA, and Java.

\end{itemize}
\subsection{OpenCV}
OpenCV (Open Source Computer Vision Library)\cite{opencv} is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. Being a BSD-licensed product, OpenCV makes it easy for businesses to utilize and modify the code.\par
The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene, find similar images from an image database, remove red eyes from images taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality, etc. OpenCV has more than 47 thousand people of user community and estimated number of downloads exceeding 14 million. The library is used extensively in companies, research groups and by governmental bodies.\par
Along with well-established companies like Google, Yahoo, Microsoft, Intel, IBM, Sony, Honda, Toyota that employ the library, there are many start-ups such as Applied Minds, VideoSurf, and Zeitera, that make extensive use of OpenCV. OpenCV’s deployed uses span the range from stitching street view images together, detecting intrusions in surveillance video in Israel, monitoring mine equipment in China, helping robots navigate and pick up objects at Willow Garage, detection of swimming pool drowning accidents in Europe, running interactive art in Spain and New York, checking runways for debris in Turkey, inspecting labels on products in factories around the world on to rapid face detection in Japan.\par
OpenCV is written in C++ and its primary interface is in C++, but it still retains a less comprehensive though extensive older C interface. There are bindings in Python, Java and MATLAB/OCTAVE. The API for these interfaces	can be found in the online documentation. Wrappers in other languages such as C-sharp, Perl, Ch, Haskell and Ruby have been developed to encourage adoption by a wider audience. All the new developments and algorithms in OpenCV are now developed in the C++ interface.\\
There are many \textbf{applications} of OpenCV. A few of them are cited as below:
\begin{itemize}
\item 2D and 3D feature toolkits 
\item Facial recognition system 
\item Gesture recognition 
\item Human Computer Interaction (HCI) 
\item Mobile robotics 
\item Motion understanding 
\item Object identification 
\item Segmentation and recognition 
\item Stereopsis stereo vision: depth perception from 2 cameras 
\item Structure From Motion (SFM) 
\item Motion tracking 
\end{itemize}
\subsection{Hardware Requirements}
\begin{itemize}
	\item Processor - Intel Core i5 5th gen
	\item RAM - 8 GB
	\item Hard Disk - 500 GB
	\item OS - Unix based such as Debian , MacOS
	\item WebCam
	\item USB 2.0 Ports
\end{itemize}
\subsection{Keras and TensorFlow}
\subsubsection{Keras}
Keras\cite{keras} is a high-level neural networks API, written in Python and capable of running on top of \textbf{TensorFlow, CNTK, or Theano}. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.
\\
Use Keras if you need a deep learning library that:
\begin{itemize}
	\item Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).
	\item Supports both convolutional networks and recurrent networks, as well as combinations of the two.
	\item Runs seamlessly on CPU and GPU.
\end{itemize}
Keras is compatible with: \textbf{Python 2.7-3.6.}
\\
\textbf{Guiding Principles:}
\begin{itemize}
	\item \textbf{User friendliness}. Keras\cite{keras} is an API designed for human beings, not machines. It puts user experience front and center. Keras follows best practices for reducing cognitive load: it offers consistent \& simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error.
	\item \textbf{Modularity}.A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as little restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules that you can combine to create new models.
	\item \textbf{Easy extensibility}. New modules are simple to add (as new classes and functions), and existing modules provide ample examples. To be able to easily create new modules allows for total expressiveness, making Keras suitable for advanced research.
	\item \textbf{Work with Python}. No separate models configuration files in a declarative format. Models are described in Python code, which is compact, easier to debug, and allows for ease of extensibility.
\end{itemize}
\subsubsection{TensorFlow}
TensorFlow\cite{tensorflow} is an open-source software library for dataflow programming across a range of tasks. It is a symbolic math library, and also used for machine learning applications such as neural networks.
\par
TensorFlow is an open source software library for numerical computation using data flow graphs. The graph nodes represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) that flow between them. This flexible architecture lets you deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device without rewriting code. TensorFlow also includes TensorBoard, a data visualization toolkit.
\par
TensorFlow was originally developed by researchers and engineers working on the Google Brain team within Google's Machine Intelligence Research organization for the purposes of conducting machine learning and deep neural networks research. The system is general enough to be applicable in a wide variety of other domains, as well.
\subsection{Others}
\subsubsection{Libraries}
Along with OpenCV we have used bob. Bob\cite{bob} is a machine learning platform used in python, it helped us to port Matlab code of optical flow to python. Scikit learn is Python package which is similar to WEKA tool for java. It will be used for training a classifier model in the proposed algorithm of the project.

\subsubsection{Editor}
An editor is required to create python source files and to view violent features generated for the dataset. Open source editors like Atom and PyCharm have been used which also provide terminal access.

\subsubsection{Video Player}
To play all the videos through openCV and to view some random videos. Video players like VLC is required which is open source. ffmpeg library is also required which provides a way to read video files through openCV. ffmpeg can also be used to format videos.


